{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e913e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyproj\n",
    "import pandas as pd\n",
    "import DBconnection\n",
    "from sqlalchemy import create_engine\n",
    "from geopy import Point\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "cursor, conn = DBconnection.get_connection()\n",
    "db = create_engine('postgresql+psycopg2://postgres:vasilis@localhost/Metro_Transit')\n",
    "conn_alchemy = db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b70844e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_last_modified=0\n",
    "iter_folder=0\n",
    "filename=0\n",
    "path=r\"C:\\Users\\bpes.MEDIS\\theses\\STATIC_DATA\"\n",
    "\n",
    "for folder_name in os.listdir(r\"C:\\Users\\bpes.MEDIS\\theses\\STATIC_DATA\"):\n",
    "    new_path=os.path.join(path,folder_name)\n",
    "    iter_folder=os.path.getmtime(new_path)\n",
    "    if iter_folder > max_last_modified:\n",
    "        max_last_modified=iter_folder\n",
    "        lates_data_path=new_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ae770eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert to feed_info\n",
      "insert to trips_tmp\n",
      "stop_stop_times\n",
      "agency_routes\n",
      "calendar_dates_calendar\n",
      "all_tables_trips\n"
     ]
    }
   ],
   "source": [
    "def feed(path):\n",
    "    print('insert to feed_info')\n",
    "    FeedInfo = pd.read_csv(path)\n",
    "    FeedInfo['feed_info_index']=FeedInfoIndex\n",
    "    FeedInfo.to_sql('feed_info',conn_alchemy,if_exists= 'append')\n",
    "\n",
    "    \n",
    "def stops(path):\n",
    "    print('insert to stops')\n",
    "    stops = pd.read_csv(path)\n",
    "    stops['feed_version']=FeedVersion\n",
    "    \n",
    "    stops.drop_duplicates(subset=['stop_id'],inplace=True)\n",
    "    stops.drop_duplicates(subset=['stop_code'],inplace=True)\n",
    "    stops.drop_duplicates(subset=['stop_name'],inplace=True)\n",
    "    stops.drop_duplicates(subset=['stop_url'],inplace=True)\n",
    "    stops.drop_duplicates(subset=['stop_lat','stop_lon'],inplace=True)\n",
    "    stops.to_sql('stops',conn_alchemy,if_exists= 'append')\n",
    "    \n",
    "\n",
    "\n",
    "def stop_times(path):\n",
    "    print('insert to stop_times')\n",
    "    stop_times = pd.read_csv(path)\n",
    "    stop_times['feed_version']=FeedVersion \n",
    "    stop_times.sort_values(by=['trip_id','stop_sequence'], ascending=True)\n",
    "    stop_times.drop_duplicates(subset=['trip_id', 'stop_sequence'],inplace=True)\n",
    "    \n",
    "    arv_time=''\n",
    "    arv_time_cnt=0\n",
    "    dep_time=''\n",
    "    dep_time_cnt=0\n",
    "    prev_trip_id=''\n",
    "    for index,row in stop_times.iterrows():\n",
    "        if(row['trip_id'] != prev_trip_id):\n",
    "            arv_time_cnt=0\n",
    "            dep_time_cnt=0\n",
    "            \n",
    "          \n",
    "        if (row['arrival_time'] >arv_time):\n",
    "            arv_time=row['arrival_time']\n",
    "            arv_time_cnt=0\n",
    "        elif (row['arrival_time']==arv_time):\n",
    "            arv_time_cnt+=1\n",
    "            \n",
    "        if (row['departure_time'] >dep_time):\n",
    "            dep_time=row['departure_time']\n",
    "            dep_time_cnt=0\n",
    "        elif(row['departure_time']==dep_time):\n",
    "            dep_time_cnt+=1\n",
    "            \n",
    "            \n",
    "        #if  arv_time_cnt >2:\n",
    "         #   stop_times=stop_times.drop(index)\n",
    "        #if  dep_time_cnt >2:\n",
    "         #   stop_times=stop_times.drop(index)   \n",
    "            \n",
    "        prev_trip_id=row['trip_id']\n",
    "          \n",
    "    \n",
    "    seq=-99999\n",
    "    prev_trip_id=''\n",
    "    print('stop_times for 1 ok')\n",
    "    for index, row in stop_times.iterrows():\n",
    "        if(row['trip_id'] != prev_trip_id):\n",
    "            seq=-99999\n",
    "        \n",
    "        if (row['stop_sequence']> seq):\n",
    "            seq=row['stop_sequence']\n",
    "        else:\n",
    "            stop_times=stop_times.drop(index)\n",
    "            \n",
    "        prev_trip_id=row['trip_id']\n",
    "        \n",
    "    stop_times.to_sql('stop_times',conn_alchemy,if_exists= 'append')\n",
    "                          \n",
    "                        \n",
    "def agency(path):\n",
    "    print('insert to agency')\n",
    "    agency = pd.read_csv(path)\n",
    "    agency['feed_version']=FeedVersion\n",
    "   # agency = agency[[\"agency_id\",\"agency_name\",\"agency_url\",\"agency_timezone\",\"agency_lang\",\"agency_phone\",\"agency_fare_url\",\"agency_email\"]]                  \n",
    "    agency.to_sql('agency',conn_alchemy,if_exists= 'append')\n",
    "\n",
    "\n",
    "\n",
    "def routes(path):\n",
    "    print('insert to routes')\n",
    "    routes = pd.read_csv(path)\n",
    "    routes['feed_version']=FeedVersion\n",
    "\n",
    "    #routes.drop_duplicates(subset=['route_id'],inplace=True)\n",
    "    #routes.drop_duplicates(subset=['route_short_name'],inplace=True)\n",
    "    #routes.drop_duplicates(subset=['route_long_name'],inplace=True)\n",
    "    #routes.drop_duplicates(subset=['route_url'],inplace=True)\n",
    "    routes.to_sql('routes',conn_alchemy,if_exists= 'append')\n",
    "    print('ok')\n",
    "\n",
    "\n",
    "def calendar_dates(path):\n",
    "    print('insert to calendar_dates')\n",
    "    stops_ok=0\n",
    "    calendar_dates = pd.read_csv(path)\n",
    "    calendar_dates['feed_version']=FeedVersion\n",
    "\n",
    "    #shapes.drop_duplicates(subset=['route_id','route_short_name','route_long_name','route_url'],inplace=True)\n",
    "    #routes.drop_duplicates(subset=['route_short_name'],inplace=True)\n",
    "    #stops.drop_duplicates(subset=['stop_name'],inplace=True)\n",
    "    #routes.drop_duplicates(subset=['route_long_name'],inplace=True)\n",
    "    #routes.drop_duplicates(subset=['route_url'],inplace=True)\n",
    "    calendar_dates.to_sql('calendar_dates',conn_alchemy,if_exists= 'append')\n",
    "\n",
    "\n",
    "\n",
    "def calendar(path):\n",
    "    print('insert to calendar')\n",
    "    calendar= pd.read_csv(path)\n",
    "    calendar['feed_version']=FeedVersion\n",
    "\n",
    "    #shapes.drop_duplicates(subset=['route_id','route_short_name','route_long_name','route_url'],inplace=True)\n",
    "    #routes.drop_duplicates(subset=['route_short_name'],inplace=True)\n",
    "    #stops.drop_duplicates(subset=['stop_name'],inplace=True)\n",
    "    #routes.drop_duplicates(subset=['route_long_name'],inplace=True)\n",
    "    #routes.drop_duplicates(subset=['route_url'],inplace=True)\n",
    "    calendar.to_sql('calendar',conn_alchemy,if_exists= 'append')\n",
    "\n",
    "\n",
    "def shapes(path):\n",
    "    print('insert to shapes')\n",
    "    stops_ok=0\n",
    "    shapes = pd.read_csv(path)\n",
    "    shapes['feed_version']=FeedVersion\n",
    "    shapes.sort_values(by=['shape_id','shape_pt_sequence'], ascending=True)\n",
    "    shapes.drop_duplicates(subset=['shape_id','shape_pt_lat','shape_pt_lon'],inplace=True)\n",
    "    '''\n",
    "    prev_shp_id=''\n",
    "    seq=0\n",
    "    for index, row in shapes.iterrows():\n",
    "        if(row['shape_id'] != prev_shp_id):\n",
    "            seq=-99999\n",
    "            \n",
    "        if (row['shape_pt_sequence'] >seq):\n",
    "            seq=row['shape_pt_sequence']\n",
    "        else:\n",
    "            shapes=shapes.drop(index)\n",
    "            \n",
    "        prev_shp_id=shapes['shape_id']'''\n",
    "    shapes.to_sql('shapes',conn_alchemy,if_exists= 'append')\n",
    "\n",
    "   \n",
    " \n",
    "    \n",
    "def trips_tmp(path):\n",
    "    print('insert to trips_tmp')\n",
    "    trips = pd.read_csv(path)\n",
    "    trips['feed_version']=FeedVersion\n",
    "\n",
    "    #trips.drop_duplicates(subset=['trip_id','route_id'],inplace=True)\n",
    "    #trips.drop_duplicates(subset=['trip_headsign',],inplace=True)\n",
    "    \n",
    "    trips.to_sql('trips_tmp',conn_alchemy, if_exists='replace')\n",
    "    \n",
    "    \n",
    "\n",
    "def vehicles(path):\n",
    "    print('insert to vehicles')\n",
    "    vehicles = pd.read_csv(path)\n",
    "    vehicles['feed_version']=FeedVersion \n",
    "    vehicles.drop_duplicates(subset=['vehicle_id'],inplace=True)\n",
    "    vehicles.drop_duplicates(subset=['vehicle_label'],inplace=True)\n",
    "    vehicles.to_sql('vehicles',conn_alchemy,if_exists= 'append')\n",
    "#################################################################################################################### \n",
    "\n",
    "\n",
    "def stop_stop_times(FeedVersion):\n",
    "    print('stop_stop_times')\n",
    "    cursor.execute(\"\"\"delete from stops \n",
    "                        where stops.feed_version=%s\n",
    "                        and  stops.stop_id not in(\n",
    "                        select distinct stops.stop_id from stops\n",
    "                        inner join stop_times\n",
    "                        on stops.stop_id = stop_times.stop_id\n",
    "                        and stops.feed_version= stop_times.feed_version\n",
    "                        where stops.feed_version=%s)\"\"\",\n",
    "                   (FeedVersion,FeedVersion,))\n",
    "    conn.commit()\n",
    "    \n",
    "\n",
    "    cursor.execute(\"\"\"delete from stop_times st_times\n",
    "                        where st_times.feed_version=%s \n",
    "                        and not exists(\n",
    "                        select stop_times.* from stop_times\n",
    "                        inner join stops\n",
    "                        on stop_times.stop_id = stops.stop_id\n",
    "                        where st_times.stop_id = stop_times.stop_id\n",
    "                        and stop_times.feed_version=%s)\n",
    "                        \"\"\",(FeedVersion,FeedVersion,))    \n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def agency_routes(FeedVersion):\n",
    "    print('agency_routes')\n",
    "    cursor.execute(\"\"\"delete from agency agc\n",
    "                        where agc.feed_version=%s\n",
    "                        and not exists(\n",
    "                        select agency.* from agency\n",
    "                        inner join routes\n",
    "                        on agency.agency_id = routes.agency_id\n",
    "                        where agc.agency_id=routes.agency_id\n",
    "                        and agency.feed_version=%s)\"\"\",\n",
    "                   (FeedVersion,FeedVersion,))\n",
    "    conn.commit()   \n",
    "    \n",
    "\n",
    "    cursor.execute(\"\"\"delete from routes rts\n",
    "                        where rts.feed_version=%s\n",
    "                         and not exists (\n",
    "                            select * from  agency\n",
    "                            inner join routes\n",
    "                            on agency.agency_id = routes.route_id\n",
    "                            where rts.agency_id = routes.agency_id\n",
    "                            and agency.feed_version = %s)\"\"\",\n",
    "                   (FeedVersion,FeedVersion,))\n",
    "    conn.commit()\n",
    "    \n",
    "    \n",
    "def calendar_dates_calendar(FeedVersion):\n",
    "    print('calendar_dates_calendar')\n",
    "    cursor.execute(\"\"\"delete from calendar_dates cal_dates\n",
    "                        where cal_dates.feed_version=%s\n",
    "                        and not exists(\n",
    "                                    select * from calendar_dates\n",
    "                                    inner join calendar\n",
    "                                    on calendar_dates.service_id = calendar.service_id\n",
    "                                    where cal_dates.service_id = calendar.service_id\n",
    "                                    and calendar_dates.feed_version=%s) \"\"\",\n",
    "                   (FeedVersion,FeedVersion,))\n",
    "    conn.commit()\n",
    "    \n",
    "    \n",
    "def all_tables_trips(FeedVersion):\n",
    "    print('all_tables_trips')\n",
    "    cursor.execute(\"\"\"insert into trips\n",
    "                    select distinct   trips_tmp.* from trips_tmp\n",
    "                    inner join stop_times\n",
    "                    on trips_tmp.trip_id = stop_times.trip_id\n",
    "                    and trips_tmp.feed_version=stop_times.feed_version\n",
    "\n",
    "                    inner join routes\n",
    "                    on trips_tmp.route_id = routes.route_id\n",
    "                    and trips_tmp.feed_version=routes.feed_version\n",
    "\n",
    "                    inner join calendar\n",
    "                    on trips_tmp.service_id = calendar.service_id\n",
    "                    and trips_tmp.feed_version=calendar.feed_version\n",
    "                     \"\"\")\n",
    "    conn.commit() \n",
    "\n",
    "####################################################################################################################\n",
    "\n",
    "def detect_spatial_problems_stops():\n",
    "    print('deterct_spatial_problems_stops')\n",
    "    cursor.execute(\"\"\"select distinct  \n",
    "                        trips.trip_id,\n",
    "                        trips.shape_id,\n",
    "                        stop_times.stop_id,\n",
    "                        stop_times.stop_sequence,\n",
    "                        stops.stop_lat, \n",
    "                        stops.stop_lon from trips \n",
    "                        inner join stop_times \n",
    "                        on trips.trip_id = stop_times.trip_id\n",
    "                        and trips.feed_version=stop_times.feed_version\n",
    "                        inner join stops \n",
    "                        on stop_times.stop_id = stops.stop_id\n",
    "                        and trips.feed_version = stops.feed_version\n",
    "                        where trips.feed_version=%s\n",
    "                        order by trips.trip_id,trips.shape_id,stop_times.stop_sequence asc;\n",
    "                        \"\"\",\n",
    "                   (FeedVersion,))\n",
    "    trips_stops = cursor.fetchall()  \n",
    "    \n",
    "    \n",
    "    cursor.execute(\"\"\"select * from shapes\n",
    "                        where shapes.feed_version = %s\n",
    "                        order by shapes.shape_id,shapes.shape_pt_sequence asc\"\"\",\n",
    "                   (FeedVersion,))\n",
    "    shapes = cursor.fetchall()   \n",
    "    \n",
    "    dist_found=0\n",
    "    shape_seq=0\n",
    "    prev_trip_id=0\n",
    "    for trips_stops_rows in trips_stops:\n",
    "        trips_stops_rows_trip_id=trips_stops_rows[0]\n",
    "        trips_stops_rows_shape_id=trips_stops_rows[1]\n",
    "        trips_stops_rows_stop_id=trips_stops_rows[2]\n",
    "        trips_stops_rows_stop_seq=trips_stops_rows[3]\n",
    "        trips_stops_rows_lat=trips_stops_rows[4]\n",
    "        trips_stops_rows_lon=trips_stops_rows[5]\n",
    "        \n",
    "        if trips_stops_rows_trip_id != prev_trip_id:\n",
    "            shape_seq=0\n",
    "        \n",
    "        dist_found=0\n",
    "        for shapes_rows in shapes:\n",
    "            shapes_rows_index=shapes_rows[0]\n",
    "            shapes_rows_shape_id=shapes_rows[1]\n",
    "            shapes_rows_lat=shapes_rows[2]\n",
    "            shapes_rows_lon=shapes_rows[3]\n",
    "            shapes_rows_shape_seq=shapes_rows[4]\n",
    "            \n",
    "            \n",
    "            if (trips_stops_rows_shape_id == shapes_rows_shape_id) and (shapes_rows_shape_seq>shape_seq):\n",
    "                trips_stops_coor=(trips_stops_rows_lat,trips_stops_rows_lon)\n",
    "                shapes_coor=(shapes_rows_lat,shapes_rows_lon)\n",
    "                dist=geodesic(trips_stops_coor, shapes_coor).m\n",
    "                \n",
    "                if dist<50:\n",
    "                    dist_found=1\n",
    "                    shape_seq=shapes_rows_shape_seq\n",
    "                \n",
    "                if dist_found==1:\n",
    "                    break\n",
    "        \n",
    "        if dist_found==0:\n",
    "            print('ok')\n",
    "        '''\n",
    "            cursor.execute(\"\"\"delete from stops\n",
    "                                where stops.feed_version=%s\n",
    "                                and stops.stop_id=%s\"\"\",\n",
    "                           (FeedVersion,trips_stops_rows_stop_id))\n",
    "            conn.commit()   \n",
    "        '''    \n",
    "\n",
    "        prev_trip_id= trips_stops_rows_trip_id  \n",
    "####################################################################################################################\n",
    "\n",
    "cursor.execute('''select  nextval('feed_info_index_seq')''')\n",
    "FeedInfoIndex = cursor.fetchone()    \n",
    "\n",
    "feed_info_path=os.path.join(lates_data_path, 'feed_info.txt')\n",
    "feed(feed_info_path)\n",
    "\n",
    "\n",
    "cursor.execute('select feed_info.feed_version from feed_info order by feed_info.feed_info_index desc limit 1')\n",
    "FeedVersion = cursor.fetchone()[0]\n",
    "\n",
    "for file_name in os.listdir(lates_data_path):\n",
    "    file_path = os.path.join(lates_data_path, file_name)\n",
    "    '''\n",
    "    if file_name =='stops.txt':\n",
    "        flag=stops(file_path)\n",
    "    \n",
    "    if file_name =='stop_times.txt':\n",
    "        flag=stop_times(file_path)\n",
    "         \n",
    "    if file_name =='agency.txt':\n",
    "        flag=agency(file_path)\n",
    "        \n",
    "    if file_name =='routes.txt':\n",
    "        flag=routes(file_path)\n",
    "        \n",
    "    if file_name =='calendar_dates.txt':\n",
    "        flag=calendar_dates(file_path)\n",
    "    \n",
    "    if file_name =='calendar.txt':\n",
    "        flag=calendar(file_path)\n",
    "    \n",
    "    if file_name =='shapes.txt':\n",
    "        flag=shapes(file_path)\n",
    "    '''\n",
    "    if file_name =='trips.txt':\n",
    "        flag=trips_tmp(file_path)\n",
    "    \n",
    "   # if file_name =='vehicles.txt':\n",
    "    #    flag=vehicles(file_path)    \n",
    "        \n",
    "\n",
    "stop_stop_times(FeedVersion)\n",
    "agency_routes(FeedVersion)\n",
    "calendar_dates_calendar(FeedVersion)\n",
    "all_tables_trips(FeedVersion)\n",
    "\n",
    "#detect_spatial_problems_stops()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d883fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
